{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM STATEMENT \n",
    "\n",
    "Reinforcement learning is being used in many disciplines from self-driving cars to chatbots. However, in a dynamic world, reinforcement learning could also be used to solve many of the world's pressing urgent issues. How do you think reinforcement learning could be used to accelerate the rate of progress towards solving one of the Sustainability and Development Goals formulated by the United Nations? Develop a Reinforcement Learning that can provide a feasible solution to one or many of the problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Reinforcement algorithm given below helps in resolving the problem of inequality in education by recommending the best action that needs to be taken by the students who are in their respective circumstances and help the students acquire quality education and also reduce inequality, therby addressing the sdg 4 and sdg 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best action for new student state: Community Outreach Programs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PersonalizedLearningRecommender:\n",
    "    def __init__(self, states, actions, learning_rate=0.1, discount_factor=0.9, epsilon=0.5):\n",
    "        self.states = states\n",
    "        self.num_states = len(states)\n",
    "        self.actions = actions\n",
    "        self.num_actions = len(actions)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.q_table = np.zeros((self.num_states, self.num_actions))\n",
    "\n",
    "    def select_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore: choose a random action\n",
    "            action = np.random.randint(self.num_actions)\n",
    "        else:\n",
    "            # Exploit: choose the action with the highest Q-value\n",
    "            action = np.argmax(self.q_table[state])\n",
    "        return action\n",
    "\n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        # Q-learning update rule\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state, best_next_action]\n",
    "        td_error = td_target - self.q_table[state, action]\n",
    "        self.q_table[state, action] += self.learning_rate * td_error\n",
    "\n",
    "# Function to simulate learning progress and return reward\n",
    "def simulate_learning(student_state, action):\n",
    "    # Simulate learning progress based on student state and action\n",
    "    # This is a simplified example, you can replace it with a more complex model\n",
    "    # For demonstration purposes, let's consider random progress with variability\n",
    "    progress_mean = 0.5  # Mean progress\n",
    "    progress_std = 0.2   # Standard deviation of progress\n",
    "    # Simulate learning progress with random variability\n",
    "    progress = np.random.normal(progress_mean, progress_std)\n",
    "    # Ensure progress is within valid range [0, 1]\n",
    "    progress = max(0, min(progress, 1))\n",
    "    # Calculate reward based on progress\n",
    "    reward = progress\n",
    "    # Simulate transition to next state based on progress\n",
    "    # This can be customized based on your domain-specific knowledge\n",
    "    next_state = (student_state + action) % recommender.num_states\n",
    "    return reward, next_state\n",
    "\n",
    "# Define the states and actions\n",
    "states = [\n",
    "    \"Novice\", \"Intermediate\", \"Advanced\",\n",
    "    \"Highly Engaged\", \"Moderately Engaged\", \"Low Engagement\",\n",
    "    \"Visual Learner\", \"Auditory Learner\", \"Kinesthetic Learner\",\n",
    "    \"Beginning of Course\", \"Midway through Course\", \"Near Completion of Course\",\n",
    "    \"Regularly Using Textbooks\", \"Actively Participating in Group Study\", \"Engaging with Online Courses\",\n",
    "    \"Attending Workshops\", \"Using Interactive Software\", \"Receiving Tutoring Sessions\",\n",
    "    \"Peer Mentoring Programs\", \"Educational Games\", \"Community Outreach Programs\",\n",
    "    \"First-Generation College Student\", \"English Language Learner\", \"Low-Income\"\n",
    "]\n",
    "\n",
    "actions = [\n",
    "    'Online Course', 'Textbook', 'Group Study', 'Interactive Software', 'Workshop',\n",
    "    'Tutoring Sessions', 'Peer Mentoring Programs', 'Educational Games',\n",
    "    'Community Outreach Programs', 'Parental Involvement Initiatives',\n",
    "    'Online Forums and Discussion Boards', 'Access to Technology',\n",
    "    'Cultural and Diversity Education', 'Career Counseling and Guidance',\n",
    "    'Financial Aid and Scholarships'\n",
    "]\n",
    "\n",
    "# Initialize the personalized learning recommender\n",
    "recommender = PersonalizedLearningRecommender(states, actions)\n",
    "\n",
    "# Increase the number of training iterations\n",
    "num_iterations = 500\n",
    "\n",
    "# Simulate learning interactions for multiple students\n",
    "num_students = 1000\n",
    "for student_id in range(num_students):\n",
    "    # Initialize student state\n",
    "    current_state = np.random.randint(recommender.num_states)\n",
    "    for _ in range(num_iterations):\n",
    "        # Increase exploration by setting a higher epsilon value\n",
    "        # for the first half of the iterations\n",
    "        if _ < num_iterations // 2:\n",
    "            recommender.epsilon = 0.8\n",
    "        else:\n",
    "            recommender.epsilon = 0.1\n",
    "        # Select action using epsilon-greedy policy\n",
    "        action = recommender.select_action(current_state)\n",
    "        # Simulate learning progress and observe reward\n",
    "        reward, next_state = simulate_learning(current_state, action)\n",
    "        # Update Q-table based on observed reward and transition\n",
    "        recommender.update_q_table(current_state, action, reward, next_state)\n",
    "        # Update current state\n",
    "        current_state = next_state\n",
    "\n",
    "# After training, the Q-table can be used to make recommendations for new students\n",
    "# For example, given a new student state, select action with the highest Q-value\n",
    "new_student_state = np.random.randint(recommender.num_states)\n",
    "best_action_index = np.argmax(recommender.q_table[new_student_state])\n",
    "best_action = actions[best_action_index]\n",
    "\n",
    "print(\"Best action for new student state:\", best_action)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
